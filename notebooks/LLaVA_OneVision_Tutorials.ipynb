{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Frustratingly Easy) LLaVA OneVision Tutorial\n",
    "\n",
    "We know that it's always beneficial to have a unified interface for different tasks. So we are trying to unify the interface for image, text, image-text interleaved, and video input. And in this tutorial, we aim to provide the most straightforward way to use our model. \n",
    "\n",
    "We use our 0.5B version as an example. This could be running on a GPU with 4GB memory. And with the following examples, you could see it's surprisingly have promising performance on understanding the image, interleaved image-text, and video. Tiny but mighty!\n",
    "\n",
    "The same code could be used for 7B model as well.\n",
    "\n",
    "## Inference Guidance\n",
    "\n",
    "First please install our repo with code and environments: pip install git+https://github.com/LLaVA-VL/LLaVA-NeXT.git\n",
    "\n",
    "Here is a quick inference code using [lmms-lab/qwen2-0.5b-si](https://huggingface.co/lmms-lab/llava-onevision-qwen2-0.5b-si) as an example. You will need to install `flash-attn` to use this code snippet. If you don't want to install it, you can set `attn_implementation=None` when load_pretrained_model\n",
    "\n",
    "### Image Input\n",
    "Tackling the single image input with LLaVA OneVision is pretty straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
      "Requirement already satisfied: torch in c:\\users\\nikit\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2.4.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\nikit\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.19.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\nikit\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2.2.2+cu121)\n",
      "Requirement already satisfied: filelock in c:\\users\\nikit\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torch) (3.13.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\nikit\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\nikit\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\nikit\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nikit\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\nikit\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\nikit\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\nikit\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torchvision) (10.2.0)\n",
      "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.5.1%2Bcu124-cp310-cp310-win_amd64.whl (4.1 MB)\n",
      "     ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
      "     ------- -------------------------------- 0.8/4.1 MB 6.7 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 3.9/4.1 MB 13.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 4.1/4.1 MB 12.4 MB/s eta 0:00:00\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.5.0%2Bcu124-cp310-cp310-win_amd64.whl (4.1 MB)\n",
      "     ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
      "     -------------------- ------------------- 2.1/4.1 MB 11.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 4.1/4.1 MB 13.1 MB/s eta 0:00:00\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.4.1%2Bcu124-cp310-cp310-win_amd64.whl (4.1 MB)\n",
      "     ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
      "     ----------------------------------- ---- 3.7/4.1 MB 16.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 4.1/4.1 MB 16.4 MB/s eta 0:00:00\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torch-2.4.1%2Bcu124-cp310-cp310-win_amd64.whl (2506.2 MB)\n",
      "     ---------------------------------------- 0.0/2.5 GB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/2.5 GB 15.3 MB/s eta 0:02:44\n",
      "     ---------------------------------------- 0.0/2.5 GB 12.7 MB/s eta 0:03:17\n",
      "     ---------------------------------------- 0.0/2.5 GB 12.5 MB/s eta 0:03:21\n",
      "     ---------------------------------------- 0.0/2.5 GB 14.2 MB/s eta 0:02:56\n",
      "     ---------------------------------------- 0.0/2.5 GB 13.5 MB/s eta 0:03:06\n",
      "     ---------------------------------------- 0.0/2.5 GB 14.3 MB/s eta 0:02:55\n",
      "     ---------------------------------------- 0.0/2.5 GB 14.1 MB/s eta 0:02:57\n",
      "     ---------------------------------------- 0.0/2.5 GB 14.7 MB/s eta 0:02:49\n",
      "     ---------------------------------------- 0.0/2.5 GB 14.9 MB/s eta 0:02:46\n",
      "     ---------------------------------------- 0.0/2.5 GB 15.0 MB/s eta 0:02:46\n",
      "      --------------------------------------- 0.0/2.5 GB 15.3 MB/s eta 0:02:42\n",
      "      --------------------------------------- 0.0/2.5 GB 15.6 MB/s eta 0:02:39\n",
      "      --------------------------------------- 0.0/2.5 GB 15.3 MB/s eta 0:02:41\n",
      "      --------------------------------------- 0.0/2.5 GB 15.2 MB/s eta 0:02:42\n",
      "      --------------------------------------- 0.0/2.5 GB 15.3 MB/s eta 0:02:42\n",
      "      --------------------------------------- 0.1/2.5 GB 15.2 MB/s eta 0:02:42\n",
      "      --------------------------------------- 0.1/2.5 GB 14.8 MB/s eta 0:02:46\n",
      "      --------------------------------------- 0.1/2.5 GB 15.1 MB/s eta 0:02:43\n",
      "      --------------------------------------- 0.1/2.5 GB 15.4 MB/s eta 0:02:39\n",
      "     - -------------------------------------- 0.1/2.5 GB 15.4 MB/s eta 0:02:39\n",
      "     - -------------------------------------- 0.1/2.5 GB 15.6 MB/s eta 0:02:36\n",
      "     - -------------------------------------- 0.1/2.5 GB 15.9 MB/s eta 0:02:34\n",
      "     - -------------------------------------- 0.1/2.5 GB 15.9 MB/s eta 0:02:33\n",
      "     - -------------------------------------- 0.1/2.5 GB 15.9 MB/s eta 0:02:33\n",
      "     - -------------------------------------- 0.1/2.5 GB 15.8 MB/s eta 0:02:34\n",
      "     - -------------------------------------- 0.1/2.5 GB 15.9 MB/s eta 0:02:33\n",
      "     - -------------------------------------- 0.1/2.5 GB 16.1 MB/s eta 0:02:31\n",
      "     - -------------------------------------- 0.1/2.5 GB 16.2 MB/s eta 0:02:30\n",
      "     - -------------------------------------- 0.1/2.5 GB 16.2 MB/s eta 0:02:30\n",
      "     - -------------------------------------- 0.1/2.5 GB 15.5 MB/s eta 0:02:36\n",
      "     - -------------------------------------- 0.1/2.5 GB 15.7 MB/s eta 0:02:34\n",
      "     - -------------------------------------- 0.1/2.5 GB 15.7 MB/s eta 0:02:33\n",
      "     - -------------------------------------- 0.1/2.5 GB 15.7 MB/s eta 0:02:33\n",
      "     - -------------------------------------- 0.1/2.5 GB 15.5 MB/s eta 0:02:35\n",
      "     - -------------------------------------- 0.1/2.5 GB 15.5 MB/s eta 0:02:35\n",
      "     - -------------------------------------- 0.1/2.5 GB 15.5 MB/s eta 0:02:34\n",
      "     - -------------------------------------- 0.1/2.5 GB 15.7 MB/s eta 0:02:33\n",
      "     - -------------------------------------- 0.1/2.5 GB 15.6 MB/s eta 0:02:33\n",
      "     - -------------------------------------- 0.1/2.5 GB 15.5 MB/s eta 0:02:34\n",
      "     -- ------------------------------------- 0.1/2.5 GB 15.5 MB/s eta 0:02:34\n",
      "     -- ------------------------------------- 0.1/2.5 GB 15.5 MB/s eta 0:02:33\n",
      "     -- ------------------------------------- 0.1/2.5 GB 15.5 MB/s eta 0:02:33\n",
      "     -- ------------------------------------- 0.1/2.5 GB 15.6 MB/s eta 0:02:33\n",
      "     -- ------------------------------------- 0.1/2.5 GB 15.6 MB/s eta 0:02:33\n",
      "     -- ------------------------------------- 0.1/2.5 GB 15.1 MB/s eta 0:02:38\n",
      "     -- ------------------------------------- 0.1/2.5 GB 15.1 MB/s eta 0:02:36\n",
      "     -- ------------------------------------- 0.1/2.5 GB 15.2 MB/s eta 0:02:36\n",
      "     -- ------------------------------------- 0.2/2.5 GB 15.3 MB/s eta 0:02:35\n",
      "     -- ------------------------------------- 0.2/2.5 GB 15.3 MB/s eta 0:02:34\n",
      "     -- ------------------------------------- 0.2/2.5 GB 15.4 MB/s eta 0:02:33\n",
      "     -- ------------------------------------- 0.2/2.5 GB 15.4 MB/s eta 0:02:33\n",
      "     -- ------------------------------------- 0.2/2.5 GB 15.4 MB/s eta 0:02:32\n",
      "     -- ------------------------------------- 0.2/2.5 GB 15.5 MB/s eta 0:02:31\n",
      "     -- ------------------------------------- 0.2/2.5 GB 15.6 MB/s eta 0:02:30\n",
      "     -- ------------------------------------- 0.2/2.5 GB 15.6 MB/s eta 0:02:30\n",
      "     -- ------------------------------------- 0.2/2.5 GB 15.6 MB/s eta 0:02:29\n",
      "     -- ------------------------------------- 0.2/2.5 GB 15.7 MB/s eta 0:02:28\n",
      "     --- ------------------------------------ 0.2/2.5 GB 15.8 MB/s eta 0:02:27\n",
      "     --- ------------------------------------ 0.2/2.5 GB 15.9 MB/s eta 0:02:26\n",
      "     --- ------------------------------------ 0.2/2.5 GB 15.9 MB/s eta 0:02:25\n",
      "     --- ------------------------------------ 0.2/2.5 GB 16.0 MB/s eta 0:02:24\n",
      "     --- ------------------------------------ 0.2/2.5 GB 16.1 MB/s eta 0:02:23\n",
      "     --- ------------------------------------ 0.2/2.5 GB 16.2 MB/s eta 0:02:22\n",
      "     --- ------------------------------------ 0.2/2.5 GB 16.2 MB/s eta 0:02:22\n",
      "     --- ------------------------------------ 0.2/2.5 GB 16.3 MB/s eta 0:02:20\n",
      "     --- ------------------------------------ 0.2/2.5 GB 16.4 MB/s eta 0:02:20\n",
      "     --- ------------------------------------ 0.2/2.5 GB 16.3 MB/s eta 0:02:20\n",
      "     --- ------------------------------------ 0.2/2.5 GB 16.3 MB/s eta 0:02:20\n",
      "     --- ------------------------------------ 0.2/2.5 GB 16.3 MB/s eta 0:02:20\n",
      "     --- ------------------------------------ 0.2/2.5 GB 16.3 MB/s eta 0:02:20\n",
      "     --- ------------------------------------ 0.2/2.5 GB 16.3 MB/s eta 0:02:20\n",
      "     --- ------------------------------------ 0.2/2.5 GB 16.3 MB/s eta 0:02:19\n",
      "     --- ------------------------------------ 0.2/2.5 GB 16.4 MB/s eta 0:02:19\n",
      "     --- ------------------------------------ 0.3/2.5 GB 16.4 MB/s eta 0:02:18\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 16.5 MB/s eta 0:02:17\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 16.6 MB/s eta 0:02:16\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 16.7 MB/s eta 0:02:14\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 16.8 MB/s eta 0:02:13\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 16.9 MB/s eta 0:02:13\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 17.1 MB/s eta 0:02:11\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 17.2 MB/s eta 0:02:10\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 17.3 MB/s eta 0:02:09\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 17.4 MB/s eta 0:02:08\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 17.4 MB/s eta 0:02:07\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 17.5 MB/s eta 0:02:07\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 17.7 MB/s eta 0:02:05\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 17.7 MB/s eta 0:02:05\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 17.9 MB/s eta 0:02:03\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 18.0 MB/s eta 0:02:02\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 17.8 MB/s eta 0:02:04\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 18.0 MB/s eta 0:02:01\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 18.0 MB/s eta 0:02:01\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 18.0 MB/s eta 0:02:01\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 18.2 MB/s eta 0:01:59\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 18.4 MB/s eta 0:01:58\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 18.4 MB/s eta 0:01:58\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 18.4 MB/s eta 0:01:58\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 18.8 MB/s eta 0:01:55\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 18.9 MB/s eta 0:01:54\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 19.0 MB/s eta 0:01:53\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 19.2 MB/s eta 0:01:51\n",
      "     ------ --------------------------------- 0.4/2.5 GB 19.4 MB/s eta 0:01:50\n",
      "     ------ --------------------------------- 0.4/2.5 GB 19.5 MB/s eta 0:01:50\n",
      "     ------ --------------------------------- 0.4/2.5 GB 19.7 MB/s eta 0:01:48\n",
      "     ------ --------------------------------- 0.4/2.5 GB 19.8 MB/s eta 0:01:47\n",
      "     ------ --------------------------------- 0.4/2.5 GB 20.0 MB/s eta 0:01:46\n",
      "     ------ --------------------------------- 0.4/2.5 GB 20.6 MB/s eta 0:01:43\n",
      "     ------ --------------------------------- 0.4/2.5 GB 20.7 MB/s eta 0:01:42\n",
      "     ------ --------------------------------- 0.4/2.5 GB 20.8 MB/s eta 0:01:41\n",
      "     ------ --------------------------------- 0.4/2.5 GB 20.7 MB/s eta 0:01:41\n",
      "     ------ --------------------------------- 0.4/2.5 GB 20.6 MB/s eta 0:01:42\n",
      "     ------ --------------------------------- 0.4/2.5 GB 21.0 MB/s eta 0:01:40\n",
      "     ------ --------------------------------- 0.4/2.5 GB 21.1 MB/s eta 0:01:39\n",
      "     ------ --------------------------------- 0.4/2.5 GB 20.9 MB/s eta 0:01:40\n",
      "     ------- -------------------------------- 0.4/2.5 GB 21.3 MB/s eta 0:01:38\n",
      "     ------- -------------------------------- 0.4/2.5 GB 21.4 MB/s eta 0:01:37\n",
      "     ------- -------------------------------- 0.4/2.5 GB 21.4 MB/s eta 0:01:37\n",
      "     ------- -------------------------------- 0.5/2.5 GB 21.5 MB/s eta 0:01:36\n",
      "     ------- -------------------------------- 0.5/2.5 GB 21.5 MB/s eta 0:01:36\n",
      "     ------- -------------------------------- 0.5/2.5 GB 21.5 MB/s eta 0:01:36\n",
      "     ------- -------------------------------- 0.5/2.5 GB 21.3 MB/s eta 0:01:36\n",
      "     ------- -------------------------------- 0.5/2.5 GB 21.2 MB/s eta 0:01:37\n",
      "     ------- -------------------------------- 0.5/2.5 GB 21.1 MB/s eta 0:01:37\n",
      "     ------- -------------------------------- 0.5/2.5 GB 20.8 MB/s eta 0:01:38\n",
      "     ------- -------------------------------- 0.5/2.5 GB 20.8 MB/s eta 0:01:38\n",
      "     ------- -------------------------------- 0.5/2.5 GB 20.7 MB/s eta 0:01:39\n",
      "     ------- -------------------------------- 0.5/2.5 GB 20.5 MB/s eta 0:01:39\n",
      "     ------- -------------------------------- 0.5/2.5 GB 20.5 MB/s eta 0:01:39\n",
      "     ------- -------------------------------- 0.5/2.5 GB 20.5 MB/s eta 0:01:39\n",
      "     ------- -------------------------------- 0.5/2.5 GB 20.8 MB/s eta 0:01:37\n",
      "     ------- -------------------------------- 0.5/2.5 GB 21.1 MB/s eta 0:01:36\n",
      "     ------- -------------------------------- 0.5/2.5 GB 20.9 MB/s eta 0:01:37\n",
      "     -------- ------------------------------- 0.5/2.5 GB 20.9 MB/s eta 0:01:36\n",
      "     -------- ------------------------------- 0.5/2.5 GB 21.0 MB/s eta 0:01:36\n",
      "     -------- ------------------------------- 0.5/2.5 GB 21.0 MB/s eta 0:01:36\n",
      "     -------- ------------------------------- 0.5/2.5 GB 21.0 MB/s eta 0:01:35\n",
      "     -------- ------------------------------- 0.5/2.5 GB 20.9 MB/s eta 0:01:35\n",
      "     -------- ------------------------------- 0.5/2.5 GB 21.0 MB/s eta 0:01:35\n",
      "     -------- ------------------------------- 0.5/2.5 GB 21.1 MB/s eta 0:01:34\n",
      "     -------- ------------------------------- 0.5/2.5 GB 21.1 MB/s eta 0:01:34\n",
      "     -------- ------------------------------- 0.5/2.5 GB 21.1 MB/s eta 0:01:34\n",
      "     -------- ------------------------------- 0.5/2.5 GB 21.1 MB/s eta 0:01:33\n",
      "     -------- ------------------------------- 0.6/2.5 GB 21.1 MB/s eta 0:01:33\n",
      "     -------- ------------------------------- 0.6/2.5 GB 21.1 MB/s eta 0:01:33\n",
      "     -------- ------------------------------- 0.6/2.5 GB 21.1 MB/s eta 0:01:33\n",
      "     -------- ------------------------------- 0.6/2.5 GB 20.6 MB/s eta 0:01:35\n",
      "     --------- ------------------------------ 0.6/2.5 GB 20.7 MB/s eta 0:01:34\n",
      "     --------- ------------------------------ 0.6/2.5 GB 20.7 MB/s eta 0:01:34\n",
      "     --------- ------------------------------ 0.6/2.5 GB 20.8 MB/s eta 0:01:33\n",
      "     --------- ------------------------------ 0.6/2.5 GB 21.1 MB/s eta 0:01:32\n",
      "     --------- ------------------------------ 0.6/2.5 GB 21.0 MB/s eta 0:01:32\n",
      "     --------- ------------------------------ 0.6/2.5 GB 21.1 MB/s eta 0:01:31\n",
      "     --------- ------------------------------ 0.6/2.5 GB 21.0 MB/s eta 0:01:32\n",
      "     --------- ------------------------------ 0.6/2.5 GB 21.0 MB/s eta 0:01:31\n",
      "     --------- ------------------------------ 0.6/2.5 GB 21.0 MB/s eta 0:01:31\n",
      "     --------- ------------------------------ 0.6/2.5 GB 21.0 MB/s eta 0:01:31\n",
      "     --------- ------------------------------ 0.6/2.5 GB 21.0 MB/s eta 0:01:31\n",
      "     --------- ------------------------------ 0.6/2.5 GB 21.0 MB/s eta 0:01:30\n",
      "     --------- ------------------------------ 0.6/2.5 GB 21.0 MB/s eta 0:01:30\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 21.1 MB/s eta 0:01:30\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 21.1 MB/s eta 0:01:29\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 21.1 MB/s eta 0:01:29\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 21.0 MB/s eta 0:01:30\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 21.0 MB/s eta 0:01:29\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 21.0 MB/s eta 0:01:29\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 21.0 MB/s eta 0:01:29\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 21.0 MB/s eta 0:01:28\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 21.0 MB/s eta 0:01:28\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 21.0 MB/s eta 0:01:28\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 21.2 MB/s eta 0:01:27\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 21.3 MB/s eta 0:01:26\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 21.4 MB/s eta 0:01:26\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 21.7 MB/s eta 0:01:24\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 21.6 MB/s eta 0:01:24\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 21.7 MB/s eta 0:01:23\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 21.7 MB/s eta 0:01:23\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 21.8 MB/s eta 0:01:23\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 22.0 MB/s eta 0:01:22\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 22.6 MB/s eta 0:01:19\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 23.4 MB/s eta 0:01:16\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 23.9 MB/s eta 0:01:14\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 24.1 MB/s eta 0:01:13\n",
      "     ------------ --------------------------- 0.8/2.5 GB 24.3 MB/s eta 0:01:13\n",
      "     ------------ --------------------------- 0.8/2.5 GB 24.6 MB/s eta 0:01:11\n",
      "     ------------ --------------------------- 0.8/2.5 GB 24.5 MB/s eta 0:01:11\n",
      "     ------------ --------------------------- 0.8/2.5 GB 24.7 MB/s eta 0:01:11\n",
      "     ------------ --------------------------- 0.8/2.5 GB 24.9 MB/s eta 0:01:10\n",
      "     ------------ --------------------------- 0.8/2.5 GB 24.7 MB/s eta 0:01:10\n",
      "     ------------ --------------------------- 0.8/2.5 GB 24.7 MB/s eta 0:01:10\n",
      "     ------------ --------------------------- 0.8/2.5 GB 24.5 MB/s eta 0:01:10\n",
      "     ------------ --------------------------- 0.8/2.5 GB 24.7 MB/s eta 0:01:10\n",
      "     ------------ --------------------------- 0.8/2.5 GB 24.8 MB/s eta 0:01:09\n",
      "     ------------ --------------------------- 0.8/2.5 GB 24.2 MB/s eta 0:01:11\n",
      "     ------------ --------------------------- 0.8/2.5 GB 24.6 MB/s eta 0:01:09\n",
      "     ------------ --------------------------- 0.8/2.5 GB 24.0 MB/s eta 0:01:11\n",
      "     ------------- -------------------------- 0.8/2.5 GB 25.0 MB/s eta 0:01:08\n",
      "     ------------- -------------------------- 0.8/2.5 GB 25.1 MB/s eta 0:01:07\n",
      "     ------------- -------------------------- 0.8/2.5 GB 25.1 MB/s eta 0:01:07\n",
      "     ------------- -------------------------- 0.8/2.5 GB 25.2 MB/s eta 0:01:07\n",
      "     ------------- -------------------------- 0.8/2.5 GB 25.3 MB/s eta 0:01:06\n",
      "     ------------- -------------------------- 0.8/2.5 GB 25.4 MB/s eta 0:01:06\n",
      "     ------------- -------------------------- 0.9/2.5 GB 25.5 MB/s eta 0:01:05\n",
      "     ------------- -------------------------- 0.9/2.5 GB 25.7 MB/s eta 0:01:05\n",
      "     ------------- -------------------------- 0.9/2.5 GB 25.9 MB/s eta 0:01:04\n",
      "     ------------- -------------------------- 0.9/2.5 GB 26.1 MB/s eta 0:01:03\n",
      "     -------------- ------------------------- 0.9/2.5 GB 26.4 MB/s eta 0:01:02\n",
      "     -------------- ------------------------- 0.9/2.5 GB 26.6 MB/s eta 0:01:02\n",
      "     -------------- ------------------------- 0.9/2.5 GB 26.8 MB/s eta 0:01:01\n",
      "     -------------- ------------------------- 0.9/2.5 GB 26.9 MB/s eta 0:01:00\n",
      "     -------------- ------------------------- 0.9/2.5 GB 27.4 MB/s eta 0:00:59\n",
      "     -------------- ------------------------- 0.9/2.5 GB 27.5 MB/s eta 0:00:58\n",
      "     -------------- ------------------------- 0.9/2.5 GB 27.8 MB/s eta 0:00:58\n",
      "     -------------- ------------------------- 0.9/2.5 GB 28.0 MB/s eta 0:00:57\n",
      "     -------------- ------------------------- 0.9/2.5 GB 28.2 MB/s eta 0:00:56\n",
      "     -------------- ------------------------- 0.9/2.5 GB 28.3 MB/s eta 0:00:56\n",
      "     --------------- ------------------------ 0.9/2.5 GB 28.5 MB/s eta 0:00:55\n",
      "     --------------- ------------------------ 1.0/2.5 GB 28.5 MB/s eta 0:00:55\n",
      "     --------------- ------------------------ 1.0/2.5 GB 28.6 MB/s eta 0:00:55\n",
      "     --------------- ------------------------ 1.0/2.5 GB 28.6 MB/s eta 0:00:54\n",
      "     --------------- ------------------------ 1.0/2.5 GB 28.5 MB/s eta 0:00:54\n",
      "     --------------- ------------------------ 1.0/2.5 GB 28.4 MB/s eta 0:00:54\n",
      "     --------------- ------------------------ 1.0/2.5 GB 28.6 MB/s eta 0:00:54\n",
      "     --------------- ------------------------ 1.0/2.5 GB 28.6 MB/s eta 0:00:53\n",
      "     --------------- ------------------------ 1.0/2.5 GB 28.6 MB/s eta 0:00:53\n",
      "     --------------- ------------------------ 1.0/2.5 GB 28.2 MB/s eta 0:00:54\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 28.4 MB/s eta 0:00:53\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 28.3 MB/s eta 0:00:53\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 28.2 MB/s eta 0:00:53\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 28.3 MB/s eta 0:00:53\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 28.6 MB/s eta 0:00:52\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 28.6 MB/s eta 0:00:52\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 28.8 MB/s eta 0:00:51\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 29.3 MB/s eta 0:00:50\n",
      "     ---------------- ----------------------- 1.1/2.5 GB 29.4 MB/s eta 0:00:50\n",
      "     ---------------- ----------------------- 1.1/2.5 GB 29.4 MB/s eta 0:00:50\n",
      "     ---------------- ----------------------- 1.1/2.5 GB 29.4 MB/s eta 0:00:50\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 30.4 MB/s eta 0:00:48\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 30.3 MB/s eta 0:00:48\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 30.3 MB/s eta 0:00:48\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 29.9 MB/s eta 0:00:48\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 29.5 MB/s eta 0:00:49\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 29.3 MB/s eta 0:00:49\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 29.1 MB/s eta 0:00:49\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 28.9 MB/s eta 0:00:49\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 28.7 MB/s eta 0:00:49\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 28.7 MB/s eta 0:00:49\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 27.8 MB/s eta 0:00:51\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 27.8 MB/s eta 0:00:51\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 27.7 MB/s eta 0:00:51\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 27.5 MB/s eta 0:00:51\n",
      "     ------------------ --------------------- 1.1/2.5 GB 27.4 MB/s eta 0:00:51\n",
      "     ------------------ --------------------- 1.1/2.5 GB 27.3 MB/s eta 0:00:51\n",
      "     ------------------ --------------------- 1.1/2.5 GB 27.1 MB/s eta 0:00:51\n",
      "     ------------------ --------------------- 1.1/2.5 GB 26.7 MB/s eta 0:00:52\n",
      "     ------------------ --------------------- 1.2/2.5 GB 26.9 MB/s eta 0:00:51\n",
      "     ------------------ --------------------- 1.2/2.5 GB 26.4 MB/s eta 0:00:52\n",
      "     ------------------ --------------------- 1.2/2.5 GB 26.3 MB/s eta 0:00:52\n",
      "     ------------------ --------------------- 1.2/2.5 GB 26.3 MB/s eta 0:00:52\n",
      "     ------------------ --------------------- 1.2/2.5 GB 26.2 MB/s eta 0:00:52\n",
      "     ------------------ --------------------- 1.2/2.5 GB 26.1 MB/s eta 0:00:52\n",
      "     ------------------ --------------------- 1.2/2.5 GB 26.0 MB/s eta 0:00:52\n",
      "     ------------------ --------------------- 1.2/2.5 GB 25.9 MB/s eta 0:00:51\n",
      "     ------------------- -------------------- 1.2/2.5 GB 25.8 MB/s eta 0:00:51\n",
      "     ------------------- -------------------- 1.2/2.5 GB 25.8 MB/s eta 0:00:51\n",
      "     ------------------- -------------------- 1.2/2.5 GB 25.6 MB/s eta 0:00:51\n",
      "     ------------------- -------------------- 1.2/2.5 GB 25.4 MB/s eta 0:00:52\n",
      "     ------------------- -------------------- 1.2/2.5 GB 25.2 MB/s eta 0:00:52\n",
      "     ------------------- -------------------- 1.2/2.5 GB 25.2 MB/s eta 0:00:52\n",
      "     ------------------- -------------------- 1.2/2.5 GB 25.1 MB/s eta 0:00:52\n",
      "     ------------------- -------------------- 1.2/2.5 GB 25.1 MB/s eta 0:00:52\n",
      "     ------------------- -------------------- 1.2/2.5 GB 24.8 MB/s eta 0:00:52\n",
      "     ------------------- -------------------- 1.2/2.5 GB 24.6 MB/s eta 0:00:52\n",
      "     ------------------- -------------------- 1.2/2.5 GB 24.6 MB/s eta 0:00:52\n",
      "     ------------------- -------------------- 1.2/2.5 GB 24.7 MB/s eta 0:00:52\n",
      "     ------------------- -------------------- 1.2/2.5 GB 24.7 MB/s eta 0:00:52\n",
      "     -------------------- ------------------- 1.3/2.5 GB 24.4 MB/s eta 0:00:52\n",
      "     -------------------- ------------------- 1.3/2.5 GB 24.4 MB/s eta 0:00:52\n",
      "     -------------------- ------------------- 1.3/2.5 GB 24.3 MB/s eta 0:00:52\n",
      "     -------------------- ------------------- 1.3/2.5 GB 24.3 MB/s eta 0:00:51\n",
      "     -------------------- ------------------- 1.3/2.5 GB 24.5 MB/s eta 0:00:51\n",
      "     -------------------- ------------------- 1.3/2.5 GB 24.1 MB/s eta 0:00:51\n",
      "     -------------------- ------------------- 1.3/2.5 GB 24.1 MB/s eta 0:00:51\n",
      "     -------------------- ------------------- 1.3/2.5 GB 24.0 MB/s eta 0:00:51\n",
      "     -------------------- ------------------- 1.3/2.5 GB 24.0 MB/s eta 0:00:51\n",
      "     -------------------- ------------------- 1.3/2.5 GB 24.0 MB/s eta 0:00:51\n",
      "     -------------------- ------------------- 1.3/2.5 GB 23.9 MB/s eta 0:00:50\n",
      "     -------------------- ------------------- 1.3/2.5 GB 23.9 MB/s eta 0:00:50\n",
      "     --------------------- ------------------ 1.3/2.5 GB 23.8 MB/s eta 0:00:50\n",
      "     --------------------- ------------------ 1.3/2.5 GB 24.1 MB/s eta 0:00:49\n",
      "     --------------------- ------------------ 1.3/2.5 GB 23.8 MB/s eta 0:00:50\n",
      "     --------------------- ------------------ 1.3/2.5 GB 23.6 MB/s eta 0:00:50\n",
      "     --------------------- ------------------ 1.3/2.5 GB 23.6 MB/s eta 0:00:50\n",
      "     --------------------- ------------------ 1.3/2.5 GB 23.5 MB/s eta 0:00:50\n",
      "     --------------------- ------------------ 1.4/2.5 GB 23.9 MB/s eta 0:00:49\n",
      "     --------------------- ------------------ 1.4/2.5 GB 24.3 MB/s eta 0:00:48\n",
      "     --------------------- ------------------ 1.4/2.5 GB 24.3 MB/s eta 0:00:48\n",
      "     --------------------- ------------------ 1.4/2.5 GB 23.7 MB/s eta 0:00:49\n",
      "     --------------------- ------------------ 1.4/2.5 GB 24.0 MB/s eta 0:00:48\n",
      "     --------------------- ------------------ 1.4/2.5 GB 24.6 MB/s eta 0:00:46\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 24.8 MB/s eta 0:00:46\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 24.7 MB/s eta 0:00:46\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 24.8 MB/s eta 0:00:45\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 24.9 MB/s eta 0:00:45\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 25.1 MB/s eta 0:00:44\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 25.2 MB/s eta 0:00:44\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 26.4 MB/s eta 0:00:42\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 25.9 MB/s eta 0:00:42\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 25.8 MB/s eta 0:00:42\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 25.9 MB/s eta 0:00:42\n",
      "     ----------------------- ---------------- 1.4/2.5 GB 25.9 MB/s eta 0:00:42\n",
      "     ----------------------- ---------------- 1.4/2.5 GB 25.7 MB/s eta 0:00:42\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 25.8 MB/s eta 0:00:41\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 25.9 MB/s eta 0:00:41\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 26.1 MB/s eta 0:00:40\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 26.4 MB/s eta 0:00:40\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 26.5 MB/s eta 0:00:39\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 26.4 MB/s eta 0:00:39\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 26.1 MB/s eta 0:00:40\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 26.4 MB/s eta 0:00:39\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 26.7 MB/s eta 0:00:38\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 26.8 MB/s eta 0:00:38\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 26.2 MB/s eta 0:00:39\n",
      "     ------------------------ --------------- 1.5/2.5 GB 25.7 MB/s eta 0:00:39\n",
      "     ------------------------ --------------- 1.5/2.5 GB 26.2 MB/s eta 0:00:39\n",
      "     ------------------------ --------------- 1.5/2.5 GB 26.2 MB/s eta 0:00:39\n",
      "     ------------------------ --------------- 1.5/2.5 GB 26.4 MB/s eta 0:00:38\n",
      "     ------------------------ --------------- 1.5/2.5 GB 26.3 MB/s eta 0:00:38\n",
      "     ------------------------ --------------- 1.5/2.5 GB 26.4 MB/s eta 0:00:37\n",
      "     ------------------------ --------------- 1.5/2.5 GB 26.6 MB/s eta 0:00:37\n",
      "     ------------------------ --------------- 1.5/2.5 GB 26.6 MB/s eta 0:00:37\n",
      "     ------------------------ --------------- 1.6/2.5 GB 26.5 MB/s eta 0:00:36\n",
      "     ------------------------ --------------- 1.6/2.5 GB 26.4 MB/s eta 0:00:36\n",
      "     ------------------------ --------------- 1.6/2.5 GB 26.4 MB/s eta 0:00:36\n",
      "     ------------------------- -------------- 1.6/2.5 GB 26.5 MB/s eta 0:00:36\n",
      "     ------------------------- -------------- 1.6/2.5 GB 26.8 MB/s eta 0:00:35\n",
      "     ------------------------- -------------- 1.6/2.5 GB 26.8 MB/s eta 0:00:35\n",
      "     ------------------------- -------------- 1.6/2.5 GB 26.9 MB/s eta 0:00:35\n",
      "     ------------------------- -------------- 1.6/2.5 GB 26.8 MB/s eta 0:00:35\n",
      "     ------------------------- -------------- 1.6/2.5 GB 26.6 MB/s eta 0:00:35\n",
      "     ------------------------- -------------- 1.6/2.5 GB 26.7 MB/s eta 0:00:34\n",
      "     ------------------------- -------------- 1.6/2.5 GB 26.3 MB/s eta 0:00:35\n",
      "     ------------------------- -------------- 1.6/2.5 GB 26.2 MB/s eta 0:00:35\n",
      "     ------------------------- -------------- 1.6/2.5 GB 25.8 MB/s eta 0:00:35\n",
      "     ------------------------- -------------- 1.6/2.5 GB 25.8 MB/s eta 0:00:35\n",
      "     ------------------------- -------------- 1.6/2.5 GB 25.8 MB/s eta 0:00:35\n",
      "     ------------------------- -------------- 1.6/2.5 GB 24.5 MB/s eta 0:00:37\n",
      "     ------------------------- -------------- 1.6/2.5 GB 24.3 MB/s eta 0:00:37\n",
      "     ------------------------- -------------- 1.6/2.5 GB 24.3 MB/s eta 0:00:37\n",
      "     ------------------------- -------------- 1.6/2.5 GB 23.6 MB/s eta 0:00:38\n",
      "     ------------------------- -------------- 1.6/2.5 GB 24.2 MB/s eta 0:00:37\n",
      "     ------------------------- -------------- 1.6/2.5 GB 23.9 MB/s eta 0:00:37\n",
      "     ------------------------- -------------- 1.6/2.5 GB 23.5 MB/s eta 0:00:38\n",
      "     -------------------------- ------------- 1.6/2.5 GB 23.3 MB/s eta 0:00:38\n",
      "     -------------------------- ------------- 1.6/2.5 GB 22.9 MB/s eta 0:00:39\n",
      "     -------------------------- ------------- 1.6/2.5 GB 23.0 MB/s eta 0:00:39\n",
      "     -------------------------- ------------- 1.6/2.5 GB 23.0 MB/s eta 0:00:39\n",
      "     -------------------------- ------------- 1.6/2.5 GB 21.9 MB/s eta 0:00:40\n",
      "     -------------------------- ------------- 1.6/2.5 GB 22.2 MB/s eta 0:00:40\n",
      "     -------------------------- ------------- 1.6/2.5 GB 21.7 MB/s eta 0:00:40\n",
      "     -------------------------- ------------- 1.6/2.5 GB 21.7 MB/s eta 0:00:40\n",
      "     -------------------------- ------------- 1.7/2.5 GB 21.5 MB/s eta 0:00:40\n",
      "     -------------------------- ------------- 1.7/2.5 GB 21.4 MB/s eta 0:00:40\n",
      "     -------------------------- ------------- 1.7/2.5 GB 21.3 MB/s eta 0:00:40\n",
      "     -------------------------- ------------- 1.7/2.5 GB 21.2 MB/s eta 0:00:40\n",
      "     -------------------------- ------------- 1.7/2.5 GB 21.1 MB/s eta 0:00:40\n",
      "     -------------------------- ------------- 1.7/2.5 GB 21.1 MB/s eta 0:00:40\n",
      "     -------------------------- ------------- 1.7/2.5 GB 21.1 MB/s eta 0:00:40\n",
      "     -------------------------- ------------- 1.7/2.5 GB 21.1 MB/s eta 0:00:39\n",
      "     --------------------------- ------------ 1.7/2.5 GB 21.0 MB/s eta 0:00:39\n",
      "     --------------------------- ------------ 1.7/2.5 GB 21.0 MB/s eta 0:00:39\n",
      "     --------------------------- ------------ 1.7/2.5 GB 21.1 MB/s eta 0:00:38\n",
      "     --------------------------- ------------ 1.7/2.5 GB 21.1 MB/s eta 0:00:38\n",
      "     --------------------------- ------------ 1.7/2.5 GB 21.1 MB/s eta 0:00:38\n",
      "     --------------------------- ------------ 1.7/2.5 GB 21.1 MB/s eta 0:00:38\n",
      "     --------------------------- ------------ 1.7/2.5 GB 21.0 MB/s eta 0:00:37\n",
      "     --------------------------- ------------ 1.7/2.5 GB 21.0 MB/s eta 0:00:37\n",
      "     --------------------------- ------------ 1.7/2.5 GB 21.0 MB/s eta 0:00:37\n",
      "     --------------------------- ------------ 1.7/2.5 GB 21.0 MB/s eta 0:00:37\n",
      "     --------------------------- ------------ 1.7/2.5 GB 21.0 MB/s eta 0:00:37\n",
      "     --------------------------- ------------ 1.8/2.5 GB 20.8 MB/s eta 0:00:37\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 21.1 MB/s eta 0:00:36\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 21.7 MB/s eta 0:00:35\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 21.2 MB/s eta 0:00:35\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 21.3 MB/s eta 0:00:35\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 21.3 MB/s eta 0:00:35\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 21.1 MB/s eta 0:00:35\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 21.1 MB/s eta 0:00:34\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 21.1 MB/s eta 0:00:34\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 21.1 MB/s eta 0:00:34\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 21.1 MB/s eta 0:00:34\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 21.1 MB/s eta 0:00:33\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 21.0 MB/s eta 0:00:33\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 20.9 MB/s eta 0:00:33\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 20.7 MB/s eta 0:00:34\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 20.5 MB/s eta 0:00:34\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 20.3 MB/s eta 0:00:34\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 20.0 MB/s eta 0:00:34\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 20.0 MB/s eta 0:00:34\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 19.7 MB/s eta 0:00:35\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 19.7 MB/s eta 0:00:35\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 19.7 MB/s eta 0:00:35\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 19.1 MB/s eta 0:00:35\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 19.0 MB/s eta 0:00:35\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 18.9 MB/s eta 0:00:35\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 18.7 MB/s eta 0:00:35\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 18.7 MB/s eta 0:00:35\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 18.6 MB/s eta 0:00:36\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 18.5 MB/s eta 0:00:36\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 18.4 MB/s eta 0:00:36\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 18.3 MB/s eta 0:00:36\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 18.3 MB/s eta 0:00:36\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 17.9 MB/s eta 0:00:36\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 17.8 MB/s eta 0:00:36\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 18.9 MB/s eta 0:00:34\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 18.7 MB/s eta 0:00:34\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 18.5 MB/s eta 0:00:35\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 18.3 MB/s eta 0:00:35\n",
      "     ------------------------------ --------- 1.9/2.5 GB 18.5 MB/s eta 0:00:34\n",
      "     ------------------------------ --------- 1.9/2.5 GB 18.3 MB/s eta 0:00:35\n",
      "     ------------------------------ --------- 1.9/2.5 GB 18.3 MB/s eta 0:00:34\n",
      "     ------------------------------ --------- 1.9/2.5 GB 18.5 MB/s eta 0:00:34\n",
      "     ------------------------------ --------- 1.9/2.5 GB 18.7 MB/s eta 0:00:33\n",
      "     ------------------------------ --------- 1.9/2.5 GB 19.3 MB/s eta 0:00:32\n",
      "     ------------------------------ --------- 1.9/2.5 GB 19.7 MB/s eta 0:00:31\n",
      "     ------------------------------ --------- 1.9/2.5 GB 19.5 MB/s eta 0:00:31\n",
      "     ------------------------------ --------- 1.9/2.5 GB 19.4 MB/s eta 0:00:31\n",
      "     ------------------------------ --------- 1.9/2.5 GB 19.5 MB/s eta 0:00:31\n",
      "     ------------------------------ --------- 1.9/2.5 GB 19.5 MB/s eta 0:00:31\n",
      "     ------------------------------ --------- 1.9/2.5 GB 19.5 MB/s eta 0:00:30\n",
      "     ------------------------------ --------- 1.9/2.5 GB 19.4 MB/s eta 0:00:30\n",
      "     ------------------------------ --------- 1.9/2.5 GB 19.4 MB/s eta 0:00:30\n",
      "     ------------------------------ --------- 1.9/2.5 GB 19.4 MB/s eta 0:00:30\n",
      "     ------------------------------ --------- 1.9/2.5 GB 19.2 MB/s eta 0:00:30\n",
      "     ------------------------------ --------- 1.9/2.5 GB 19.2 MB/s eta 0:00:30\n",
      "     ------------------------------- -------- 1.9/2.5 GB 18.9 MB/s eta 0:00:30\n",
      "     ------------------------------- -------- 1.9/2.5 GB 18.7 MB/s eta 0:00:30\n",
      "     ------------------------------- -------- 2.0/2.5 GB 18.7 MB/s eta 0:00:30\n",
      "     ------------------------------- -------- 2.0/2.5 GB 18.4 MB/s eta 0:00:30\n",
      "     ------------------------------- -------- 2.0/2.5 GB 18.4 MB/s eta 0:00:30\n",
      "     ------------------------------- -------- 2.0/2.5 GB 18.4 MB/s eta 0:00:30\n",
      "     ------------------------------- -------- 2.0/2.5 GB 18.4 MB/s eta 0:00:30\n",
      "     ------------------------------- -------- 2.0/2.5 GB 18.3 MB/s eta 0:00:30\n",
      "     ------------------------------- -------- 2.0/2.5 GB 18.2 MB/s eta 0:00:30\n",
      "     ------------------------------- -------- 2.0/2.5 GB 18.1 MB/s eta 0:00:30\n",
      "     ------------------------------- -------- 2.0/2.5 GB 18.0 MB/s eta 0:00:30\n",
      "     ------------------------------- -------- 2.0/2.5 GB 17.8 MB/s eta 0:00:30\n",
      "     ------------------------------- -------- 2.0/2.5 GB 17.6 MB/s eta 0:00:30\n",
      "     ------------------------------- -------- 2.0/2.5 GB 17.4 MB/s eta 0:00:30\n",
      "     ------------------------------- -------- 2.0/2.5 GB 17.3 MB/s eta 0:00:30\n",
      "     ------------------------------- -------- 2.0/2.5 GB 17.0 MB/s eta 0:00:31\n",
      "     ------------------------------- -------- 2.0/2.5 GB 17.0 MB/s eta 0:00:31\n",
      "     ------------------------------- -------- 2.0/2.5 GB 17.0 MB/s eta 0:00:31\n",
      "     ------------------------------- -------- 2.0/2.5 GB 16.4 MB/s eta 0:00:32\n",
      "     ------------------------------- -------- 2.0/2.5 GB 16.3 MB/s eta 0:00:32\n",
      "     ------------------------------- -------- 2.0/2.5 GB 16.3 MB/s eta 0:00:32\n",
      "     ------------------------------- -------- 2.0/2.5 GB 16.1 MB/s eta 0:00:32\n",
      "     ------------------------------- -------- 2.0/2.5 GB 15.9 MB/s eta 0:00:32\n",
      "     -------------------------------- ------- 2.0/2.5 GB 15.8 MB/s eta 0:00:32\n",
      "     -------------------------------- ------- 2.0/2.5 GB 15.7 MB/s eta 0:00:32\n",
      "     -------------------------------- ------- 2.0/2.5 GB 15.6 MB/s eta 0:00:32\n",
      "     -------------------------------- ------- 2.0/2.5 GB 15.6 MB/s eta 0:00:32\n",
      "     -------------------------------- ------- 2.0/2.5 GB 15.4 MB/s eta 0:00:33\n",
      "     -------------------------------- ------- 2.0/2.5 GB 15.3 MB/s eta 0:00:33\n",
      "     -------------------------------- ------- 2.0/2.5 GB 15.2 MB/s eta 0:00:33\n",
      "     -------------------------------- ------- 2.0/2.5 GB 15.0 MB/s eta 0:00:33\n",
      "     -------------------------------- ------- 2.0/2.5 GB 14.8 MB/s eta 0:00:33\n",
      "     -------------------------------- ------- 2.0/2.5 GB 14.9 MB/s eta 0:00:33\n",
      "     -------------------------------- ------- 2.0/2.5 GB 14.8 MB/s eta 0:00:33\n",
      "     -------------------------------- ------- 2.0/2.5 GB 14.6 MB/s eta 0:00:34\n",
      "     -------------------------------- ------- 2.0/2.5 GB 14.4 MB/s eta 0:00:34\n",
      "     -------------------------------- ------- 2.0/2.5 GB 14.5 MB/s eta 0:00:34\n",
      "     -------------------------------- ------- 2.0/2.5 GB 14.4 MB/s eta 0:00:34\n",
      "     -------------------------------- ------- 2.0/2.5 GB 14.3 MB/s eta 0:00:34\n",
      "     -------------------------------- ------- 2.0/2.5 GB 14.3 MB/s eta 0:00:33\n",
      "     -------------------------------- ------- 2.0/2.5 GB 14.2 MB/s eta 0:00:33\n",
      "     -------------------------------- ------- 2.0/2.5 GB 14.1 MB/s eta 0:00:33\n",
      "     -------------------------------- ------- 2.0/2.5 GB 14.1 MB/s eta 0:00:33\n",
      "     -------------------------------- ------- 2.1/2.5 GB 14.0 MB/s eta 0:00:33\n",
      "     -------------------------------- ------- 2.1/2.5 GB 14.0 MB/s eta 0:00:33\n",
      "     -------------------------------- ------- 2.1/2.5 GB 13.9 MB/s eta 0:00:33\n",
      "     -------------------------------- ------- 2.1/2.5 GB 13.9 MB/s eta 0:00:32\n",
      "     --------------------------------- ------ 2.1/2.5 GB 13.9 MB/s eta 0:00:32\n",
      "     --------------------------------- ------ 2.1/2.5 GB 13.9 MB/s eta 0:00:32\n",
      "     --------------------------------- ------ 2.1/2.5 GB 13.9 MB/s eta 0:00:31\n",
      "     --------------------------------- ------ 2.1/2.5 GB 13.9 MB/s eta 0:00:31\n",
      "     --------------------------------- ------ 2.1/2.5 GB 14.0 MB/s eta 0:00:30\n",
      "     --------------------------------- ------ 2.1/2.5 GB 14.1 MB/s eta 0:00:30\n",
      "     --------------------------------- ------ 2.1/2.5 GB 14.8 MB/s eta 0:00:28\n",
      "     --------------------------------- ------ 2.1/2.5 GB 14.6 MB/s eta 0:00:28\n",
      "     --------------------------------- ------ 2.1/2.5 GB 14.6 MB/s eta 0:00:28\n",
      "     --------------------------------- ------ 2.1/2.5 GB 14.8 MB/s eta 0:00:27\n",
      "     --------------------------------- ------ 2.1/2.5 GB 15.0 MB/s eta 0:00:26\n",
      "     --------------------------------- ------ 2.1/2.5 GB 15.3 MB/s eta 0:00:25\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 15.8 MB/s eta 0:00:24\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 16.0 MB/s eta 0:00:24\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 16.3 MB/s eta 0:00:23\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 16.5 MB/s eta 0:00:22\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 16.7 MB/s eta 0:00:21\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 16.9 MB/s eta 0:00:21\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 17.0 MB/s eta 0:00:20\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 17.1 MB/s eta 0:00:20\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 17.2 MB/s eta 0:00:19\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 17.3 MB/s eta 0:00:19\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 17.4 MB/s eta 0:00:18\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 17.7 MB/s eta 0:00:18\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 18.0 MB/s eta 0:00:17\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 18.1 MB/s eta 0:00:17\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 18.5 MB/s eta 0:00:16\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 18.5 MB/s eta 0:00:16\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 18.5 MB/s eta 0:00:15\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 18.7 MB/s eta 0:00:15\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 18.9 MB/s eta 0:00:14\n",
      "     ----------------------------------- ---- 2.3/2.5 GB 20.1 MB/s eta 0:00:13\n",
      "     ------------------------------------ --- 2.3/2.5 GB 21.4 MB/s eta 0:00:12\n",
      "     ------------------------------------ --- 2.3/2.5 GB 22.1 MB/s eta 0:00:11\n",
      "     ------------------------------------ --- 2.3/2.5 GB 23.4 MB/s eta 0:00:10\n",
      "     ------------------------------------ --- 2.3/2.5 GB 24.4 MB/s eta 0:00:10\n",
      "     ------------------------------------ --- 2.3/2.5 GB 24.2 MB/s eta 0:00:10\n",
      "     ------------------------------------ --- 2.3/2.5 GB 25.6 MB/s eta 0:00:09\n",
      "     ------------------------------------ --- 2.3/2.5 GB 26.4 MB/s eta 0:00:09\n",
      "     ------------------------------------ --- 2.3/2.5 GB 26.9 MB/s eta 0:00:08\n",
      "     ------------------------------------ --- 2.3/2.5 GB 27.3 MB/s eta 0:00:08\n",
      "     ------------------------------------ --- 2.3/2.5 GB 27.8 MB/s eta 0:00:08\n",
      "     ------------------------------------ --- 2.3/2.5 GB 28.3 MB/s eta 0:00:07\n",
      "     ------------------------------------- -- 2.3/2.5 GB 28.6 MB/s eta 0:00:07\n",
      "     ------------------------------------- -- 2.3/2.5 GB 28.8 MB/s eta 0:00:07\n",
      "     ------------------------------------- -- 2.3/2.5 GB 29.1 MB/s eta 0:00:06\n",
      "     ------------------------------------- -- 2.3/2.5 GB 29.6 MB/s eta 0:00:06\n",
      "     ------------------------------------- -- 2.4/2.5 GB 29.8 MB/s eta 0:00:06\n",
      "     ------------------------------------- -- 2.4/2.5 GB 30.3 MB/s eta 0:00:05\n",
      "     ------------------------------------- -- 2.4/2.5 GB 30.3 MB/s eta 0:00:05\n",
      "     ------------------------------------- -- 2.4/2.5 GB 30.6 MB/s eta 0:00:05\n",
      "     ------------------------------------- -- 2.4/2.5 GB 30.7 MB/s eta 0:00:05\n",
      "     -------------------------------------- - 2.4/2.5 GB 30.8 MB/s eta 0:00:04\n",
      "     -------------------------------------- - 2.4/2.5 GB 30.9 MB/s eta 0:00:04\n",
      "     -------------------------------------- - 2.4/2.5 GB 31.0 MB/s eta 0:00:04\n",
      "     -------------------------------------- - 2.4/2.5 GB 31.1 MB/s eta 0:00:04\n",
      "     -------------------------------------- - 2.4/2.5 GB 31.2 MB/s eta 0:00:04\n",
      "     -------------------------------------- - 2.4/2.5 GB 31.2 MB/s eta 0:00:03\n",
      "     -------------------------------------- - 2.4/2.5 GB 31.2 MB/s eta 0:00:03\n",
      "     -------------------------------------- - 2.4/2.5 GB 31.2 MB/s eta 0:00:03\n",
      "     -------------------------------------- - 2.4/2.5 GB 31.1 MB/s eta 0:00:03\n",
      "     ---------------------------------------  2.4/2.5 GB 31.2 MB/s eta 0:00:03\n",
      "     ---------------------------------------  2.5/2.5 GB 31.2 MB/s eta 0:00:02\n",
      "     ---------------------------------------  2.5/2.5 GB 31.2 MB/s eta 0:00:02\n",
      "     ---------------------------------------  2.5/2.5 GB 31.3 MB/s eta 0:00:02\n",
      "     ---------------------------------------  2.5/2.5 GB 31.4 MB/s eta 0:00:02\n",
      "     ---------------------------------------  2.5/2.5 GB 31.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 31.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 31.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 31.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 31.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 31.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 31.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 31.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 31.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 31.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 31.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 31.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 31.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 31.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 31.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 31.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 31.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 31.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 31.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 31.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 31.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 31.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 31.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 31.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 31.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.5/2.5 GB 21.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nikit\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\nikit\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from sympy->torch) (1.3.0)\n",
      "Installing collected packages: torch, torchaudio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.4.1\n",
      "    Uninstalling torch-2.4.1:\n",
      "      Successfully uninstalled torch-2.4.1\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 2.2.2+cu121\n",
      "    Uninstalling torchaudio-2.2.2+cu121:\n",
      "      Successfully uninstalled torchaudio-2.2.2+cu121\n",
      "Successfully installed torch-2.4.1+cu124 torchaudio-2.4.1+cu124\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\nikit\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\~-rch'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "lightautoml 0.3.8.1 requires torch<=2.0.0,>=1.9.0, but you have torch 2.4.1+cu124 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///C:/Users/nikit/Desktop/%D0%A3%D1%87%D0%B5%D0%B1%D0%B0/%D0%A5%D0%B0%D1%85%D0%B0%D1%82%D0%BE%D0%BD/%D0%9F%D0%94%D0%94/LLaVA-NeXT\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Checking if build backend supports build_editable: started\n",
      "  Checking if build backend supports build_editable: finished with status 'done'\n",
      "  Getting requirements to build editable: started\n",
      "  Getting requirements to build editable: finished with status 'done'\n",
      "  Preparing editable metadata (pyproject.toml): started\n",
      "  Preparing editable metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting transformers@ git+https://github.com/huggingface/transformers.git@1c39974a4c4036fd641bc1191cc32799f85715a4 (from llava==1.7.0.dev0)\n",
      "  Cloning https://github.com/huggingface/transformers.git (to revision 1c39974a4c4036fd641bc1191cc32799f85715a4) to c:\\users\\nikit\\appdata\\local\\temp\\pip-install-vzvm8ozb\\transformers_95ab228521ec438896a5efd1ba52ea51\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit 1c39974a4c4036fd641bc1191cc32799f85715a4\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting numpy==1.26.1 (from llava==1.7.0.dev0)\n",
      "  Using cached numpy-1.26.1-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Collecting open-clip-torch (from llava==1.7.0.dev0)\n",
      "  Using cached open_clip_torch-2.29.0-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: fastapi in c:\\users\\nikit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llava==1.7.0.dev0) (0.115.3)\n",
      "Collecting markdown2[all] (from llava==1.7.0.dev0)\n",
      "  Using cached markdown2-2.5.1-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\nikit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llava==1.7.0.dev0) (2.32.3)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\nikit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from llava==1.7.0.dev0) (0.2.0)\n",
      "INFO: pip is looking at multiple versions of llava[train] to determine which version is compatible with other requirements. This could take a while.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~lama-index (c:\\Users\\nikit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "  WARNING: Ignoring invalid distribution ~lama-index (c:\\Users\\nikit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git 'C:\\Users\\nikit\\AppData\\Local\\Temp\\pip-install-vzvm8ozb\\transformers_95ab228521ec438896a5efd1ba52ea51'\n",
      "  Running command git rev-parse -q --verify 'sha^1c39974a4c4036fd641bc1191cc32799f85715a4'\n",
      "  Running command git fetch -q https://github.com/huggingface/transformers.git 1c39974a4c4036fd641bc1191cc32799f85715a4\n",
      "  Running command git checkout -q 1c39974a4c4036fd641bc1191cc32799f85715a4\n",
      "ERROR: Ignored the following versions that require a different python version: 1.21.2 Requires-Python >=3.7,<3.11; 1.21.3 Requires-Python >=3.7,<3.11; 1.21.4 Requires-Python >=3.7,<3.11; 1.21.5 Requires-Python >=3.7,<3.11; 1.21.6 Requires-Python >=3.7,<3.11\n",
      "ERROR: Could not find a version that satisfies the requirement torch==2.1.2; extra == \"train\" (from llava[train]) (from versions: 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1)\n",
      "ERROR: No matching distribution found for torch==2.1.2; extra == \"train\"\n"
     ]
    }
   ],
   "source": [
    "%pip install -e \".[train]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install pyav to use video processing functions.\n",
      "OpenCLIP not installed\n",
      "Loaded LLaVA model: lmms-lab/llava-onevision-qwen2-0.5b-si\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de8a30c0b7f943108662bed72b48a697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e89de79c60c47b1bd361c5e40fcf7b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c609c98bae124445a87f18a8d59326f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3555d6bf485e4a44ad04020c0d9cdebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54633a2a854f4f76bb20740e2e18f910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/101 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29df5b07a1b64d3fa32a4c11ab17e0dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/367 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "758eeb80552a436e97a2da1482f70a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/3.03k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_qwen. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "189282cbae394adcabadbcfd366b17cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.79G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vision tower: google/siglip-so400m-patch14-384\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "febcd48a3b854d78972a63132468f266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/576 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28db28b4a104458785190ce8ed86a936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.51G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "662a745f20cc4bcfa3ae5c6afe4860f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/247 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Class: LlavaQwenForCausalLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm\\'s score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and red for LLaVA-1.5. The chart appears to be comparing the performance of these algorithms across various domains or tasks, which could be related to classification, clustering, or some form of data analysis.']\n"
     ]
    }
   ],
   "source": [
    "from llava.model.builder import load_pretrained_model\n",
    "from llava.mm_utils import get_model_name_from_path, process_images, tokenizer_image_token\n",
    "from llava.constants import IMAGE_TOKEN_INDEX, DEFAULT_IMAGE_TOKEN, DEFAULT_IM_START_TOKEN, DEFAULT_IM_END_TOKEN, IGNORE_INDEX\n",
    "from llava.conversation import conv_templates, SeparatorStyle\n",
    "\n",
    "from PIL import Image\n",
    "import requests\n",
    "import copy\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pretrained = \"lmms-lab/llava-onevision-qwen2-0.5b-si\"\n",
    "model_name = \"llava_qwen\"\n",
    "device = \"cuda\"\n",
    "device_map = \"auto\"\n",
    "llava_model_args = {\n",
    "    \"multimodal\": True,\n",
    "    \"attn_implementation\": \"sdpa\",\n",
    "}\n",
    "tokenizer, model, image_processor, max_length = load_pretrained_model(pretrained, None, model_name, device_map=device_map, **llava_model_args)  # Add any other thing you want to pass in llava_model_args\n",
    "\n",
    "model.eval()\n",
    "\n",
    "url = \"https://github.com/haotian-liu/LLaVA/blob/1a91fc274d7c35a9b50b3cb29c4247ae5837ce39/images/llava_v1_5_radar.jpg?raw=true\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "image_tensor = process_images([image], image_processor, model.config)\n",
    "image_tensor = [_image.to(dtype=torch.float16, device=device) for _image in image_tensor]\n",
    "\n",
    "conv_template = \"qwen_1_5\"  # Make sure you use correct chat template for different models\n",
    "question = DEFAULT_IMAGE_TOKEN + \"\\nWhat is shown in this image?\"\n",
    "conv = copy.deepcopy(conv_templates[conv_template])\n",
    "conv.append_message(conv.roles[0], question)\n",
    "conv.append_message(conv.roles[1], None)\n",
    "prompt_question = conv.get_prompt()\n",
    "\n",
    "input_ids = tokenizer_image_token(prompt_question, tokenizer, IMAGE_TOKEN_INDEX, return_tensors=\"pt\").unsqueeze(0).to(device)\n",
    "image_sizes = [image.size]\n",
    "\n",
    "\n",
    "cont = model.generate(\n",
    "    input_ids,\n",
    "    images=image_tensor,\n",
    "    image_sizes=image_sizes,\n",
    "    do_sample=False,\n",
    "    temperature=0,\n",
    "    max_new_tokens=4096,\n",
    ")\n",
    "text_outputs = tokenizer.batch_decode(cont, skip_special_tokens=True)\n",
    "print(text_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could use the following code to make it streaming in terminal, this would be pretty useful when creating a chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The \n",
      "The image \n",
      "The image is \n",
      "The image is a \n",
      "The image is a radar \n",
      "The image is a radar chart \n",
      "The image is a radar chart that \n",
      "The image is a radar chart that shows \n",
      "The image is a radar chart that shows the \n",
      "The image is a radar chart that shows the performance \n",
      "The image is a radar chart that shows the performance of \n",
      "The image is a radar chart that shows the performance of different \n",
      "The image is a radar chart that shows the performance of different algorithms \n",
      "The image is a radar chart that shows the performance of different algorithms or \n",
      "The image is a radar chart that shows the performance of different algorithms or models \n",
      "The image is a radar chart that shows the performance of different algorithms or models in \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and red \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and red for \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and red for \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and red for \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and red for \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and red for \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and red for \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and red for \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and red for \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and red for LLaVA-1.5. \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and red for LLaVA-1.5. The \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and red for LLaVA-1.5. The chart \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and red for LLaVA-1.5. The chart appears \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and red for LLaVA-1.5. The chart appears to \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and red for LLaVA-1.5. The chart appears to be \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and red for LLaVA-1.5. The chart appears to be comparing \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and red for LLaVA-1.5. The chart appears to be comparing the \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and red for LLaVA-1.5. The chart appears to be comparing the performance \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and red for LLaVA-1.5. The chart appears to be comparing the performance of \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and red for LLaVA-1.5. The chart appears to be comparing the performance of these \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and red for LLaVA-1.5. The chart appears to be comparing the performance of these algorithms \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and red for LLaVA-1.5. The chart appears to be comparing the performance of these algorithms across \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and red for LLaVA-1.5. The chart appears to be comparing the performance of these algorithms across various \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and red for LLaVA-1.5. The chart appears to be comparing the performance of these algorithms across various domains \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and red for LLaVA-1.5. The chart appears to be comparing the performance of these algorithms across various domains or \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and red for LLaVA-1.5. The chart appears to be comparing the performance of these algorithms across various domains or \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and red for LLaVA-1.5. The chart appears to be comparing the performance of these algorithms across various domains or tasks, \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and red for LLaVA-1.5. The chart appears to be comparing the performance of these algorithms across various domains or tasks, which \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and red for LLaVA-1.5. The chart appears to be comparing the performance of these algorithms across various domains or tasks, which could \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and red for LLaVA-1.5. The chart appears to be comparing the performance of these algorithms across various domains or tasks, which could be \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and red for LLaVA-1.5. The chart appears to be comparing the performance of these algorithms across various domains or tasks, which could be related \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and red for LLaVA-1.5. The chart appears to be comparing the performance of these algorithms across various domains or tasks, which could be related to \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and red for LLaVA-1.5. The chart appears to be comparing the performance of these algorithms across various domains or tasks, which could be related to \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and red for LLaVA-1.5. The chart appears to be comparing the performance of these algorithms across various domains or tasks, which could be related to classification, \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and red for LLaVA-1.5. The chart appears to be comparing the performance of these algorithms across various domains or tasks, which could be related to classification, \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and red for LLaVA-1.5. The chart appears to be comparing the performance of these algorithms across various domains or tasks, which could be related to classification, clustering, \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and red for LLaVA-1.5. The chart appears to be comparing the performance of these algorithms across various domains or tasks, which could be related to classification, clustering, or \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and red for LLaVA-1.5. The chart appears to be comparing the performance of these algorithms across various domains or tasks, which could be related to classification, clustering, or some \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and red for LLaVA-1.5. The chart appears to be comparing the performance of these algorithms across various domains or tasks, which could be related to classification, clustering, or some form \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and red for LLaVA-1.5. The chart appears to be comparing the performance of these algorithms across various domains or tasks, which could be related to classification, clustering, or some form of \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and red for LLaVA-1.5. The chart appears to be comparing the performance of these algorithms across various domains or tasks, which could be related to classification, clustering, or some form of data \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and red for LLaVA-1.5. The chart appears to be comparing the performance of these algorithms across various domains or tasks, which could be related to classification, clustering, or some form of data \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and red for LLaVA-1.5. The chart appears to be comparing the performance of these algorithms across various domains or tasks, which could be related to classification, clustering, or some form of data \n",
      "The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and red for LLaVA-1.5. The chart appears to be comparing the performance of these algorithms across various domains or tasks, which could be related to classification, clustering, or some form of data analysis.\n",
      "Final output: The image is a radar chart that shows the performance of different algorithms or models in a specific domain, such as machine learning or natural language processing. The chart has several axes and labels indicating the algorithm names, their respective scores, and possibly other metrics like \"BLIP-2,\" \"InstructionBLIP,\" \"Qwen-VL-Chat,\" and \"LLaVA-1.5.\" Each algorithm's score is represented by a color-coded line on the chart, with blue representing BLIP-2, green for InstructionBLIP, orange for Qwen-VL-Chat, and red for LLaVA-1.5. The chart appears to be comparing the performance of these algorithms across various domains or tasks, which could be related to classification, clustering, or some form of data analysis.\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread\n",
    "from transformers import TextIteratorStreamer\n",
    "import json\n",
    "\n",
    "url = \"https://github.com/haotian-liu/LLaVA/blob/1a91fc274d7c35a9b50b3cb29c4247ae5837ce39/images/llava_v1_5_radar.jpg?raw=true\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "image_tensor = process_images([image], image_processor, model.config)\n",
    "image_tensor = [_image.to(dtype=torch.float16, device=device) for _image in image_tensor]\n",
    "\n",
    "conv_template = \"qwen_1_5\"\n",
    "question = DEFAULT_IMAGE_TOKEN + \"\\nWhat is shown in this image?\"\n",
    "conv = copy.deepcopy(conv_templates[conv_template])\n",
    "conv.append_message(conv.roles[0], question)\n",
    "conv.append_message(conv.roles[1], None)\n",
    "prompt_question = conv.get_prompt()\n",
    "\n",
    "input_ids = tokenizer_image_token(prompt_question, tokenizer, IMAGE_TOKEN_INDEX, return_tensors=\"pt\").unsqueeze(0).to(device)\n",
    "image_sizes = [image.size]\n",
    "\n",
    "max_context_length = getattr(model.config, \"max_position_embeddings\", 2048)\n",
    "num_image_tokens = question.count(DEFAULT_IMAGE_TOKEN) * model.get_vision_tower().num_patches\n",
    "\n",
    "streamer = TextIteratorStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True, timeout=15)\n",
    "\n",
    "max_new_tokens = min(4096, max_context_length - input_ids.shape[-1] - num_image_tokens)\n",
    "\n",
    "if max_new_tokens < 1:\n",
    "    print(\n",
    "        json.dumps(\n",
    "            {\n",
    "                \"text\": question + \"Exceeds max token length. Please start a new conversation, thanks.\",\n",
    "                \"error_code\": 0,\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    gen_kwargs = {\n",
    "        \"do_sample\": False,\n",
    "        \"temperature\": 0,\n",
    "        \"max_new_tokens\": max_new_tokens,\n",
    "        \"images\": image_tensor,\n",
    "        \"image_sizes\": image_sizes,\n",
    "    }\n",
    "\n",
    "    thread = Thread(\n",
    "        target=model.generate,\n",
    "        kwargs=dict(\n",
    "            inputs=input_ids,\n",
    "            streamer=streamer,\n",
    "            **gen_kwargs,\n",
    "        ),\n",
    "    )\n",
    "    thread.start()\n",
    "\n",
    "    generated_text = \"\"\n",
    "    for new_text in streamer:\n",
    "        generated_text += new_text\n",
    "        print(generated_text, flush=True)\n",
    "        # print(json.dumps({\"text\": generated_text, \"error_code\": 0}), flush=True)\n",
    "\n",
    "    print(\"Final output:\", generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image-Text Interleaved Input\n",
    "\n",
    "Now switching to our onevision model for more complex tasks. You should start to use `llava-onevision-qwen2-0.5b-ov` for image-text interleaved input and video input.\n",
    "\n",
    "Processing image-text interleaved input is a bit more complicated. But following the code below should work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "pretrained = \"lmms-lab/llava-onevision-qwen2-0.5b-ov\"\n",
    "model_name = \"llava_qwen\"\n",
    "device = \"cuda\"\n",
    "device_map = \"auto\"\n",
    "llava_model_args = {\n",
    "        \"multimodal\": True,\n",
    "    }\n",
    "overwrite_config = {}\n",
    "overwrite_config[\"image_aspect_ratio\"] = \"pad\"\n",
    "llava_model_args[\"overwrite_config\"] = overwrite_config\n",
    "tokenizer, model, image_processor, max_length = load_pretrained_model(pretrained, None, model_name, device_map=device_map, **llava_model_args)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Load two images\n",
    "url1 = \"https://github.com/haotian-liu/LLaVA/blob/1a91fc274d7c35a9b50b3cb29c4247ae5837ce39/images/llava_v1_5_radar.jpg?raw=true\"\n",
    "url2 = \"https://raw.githubusercontent.com/haotian-liu/LLaVA/main/images/llava_logo.png\"\n",
    "\n",
    "image1 = Image.open(requests.get(url1, stream=True).raw)\n",
    "image2 = Image.open(requests.get(url2, stream=True).raw)\n",
    "\n",
    "images = [image1, image2]\n",
    "image_tensors = process_images(images, image_processor, model.config)\n",
    "image_tensors = [_image.to(dtype=torch.float16, device=device) for _image in image_tensors]\n",
    "\n",
    "# Prepare interleaved text-image input\n",
    "conv_template = \"qwen_1_5\"\n",
    "question = f\"{DEFAULT_IMAGE_TOKEN} This is the first image. Can you describe what you see?\\n\\nNow, let's look at another image: {DEFAULT_IMAGE_TOKEN}\\nWhat's the difference between these two images?\"\n",
    "\n",
    "conv = copy.deepcopy(conv_templates[conv_template])\n",
    "conv.append_message(conv.roles[0], question)\n",
    "conv.append_message(conv.roles[1], None)\n",
    "prompt_question = conv.get_prompt()\n",
    "\n",
    "input_ids = tokenizer_image_token(prompt_question, tokenizer, IMAGE_TOKEN_INDEX, return_tensors=\"pt\").unsqueeze(0).to(device)\n",
    "image_sizes = [image.size for image in images]\n",
    "\n",
    "# Generate response\n",
    "cont = model.generate(\n",
    "    input_ids,\n",
    "    images=image_tensors,\n",
    "    image_sizes=image_sizes,\n",
    "    do_sample=False,\n",
    "    temperature=0,\n",
    "    max_new_tokens=4096,\n",
    ")\n",
    "text_outputs = tokenizer.batch_decode(cont, skip_special_tokens=True)\n",
    "print(text_outputs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Input\n",
    "\n",
    "Now let's try video input. It's the same as image input, but you need to pass in a list of video frames. And remember to set the `<image>` token only once in the prompt, e.g. \"<image>\\nWhat is shown in this video?\", not \"<image>\\n<image>\\n<image>\\nWhat is shown in this video?\". Since we trained on this format, it's important to keep the format consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCLIP not installed\n",
      "Loaded LLaVA model: lmms-lab/llava-onevision-qwen2-7b-ov\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_qwen. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vision tower: google/siglip-so400m-patch14-384\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a3c8621103341739c4821581bae72e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Class: LlavaQwenForCausalLM\n",
      "(2, 1080, 1920, 3)\n",
      "torch.Size([2, 3, 384, 384])\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Cannot copy out of meta tensor; no data!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 66\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(image_tensors[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Generate response\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m cont \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvideo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m text_outputs \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(cont, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28mprint\u001b[39m(text_outputs[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\nikit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nikit\\Desktop\\\\\\\\LLaVA-NeXT\\llava\\model\\language_model\\llava_qwen.py:131\u001b[0m, in \u001b[0;36mLlavaQwenForCausalLM.generate\u001b[1;34m(self, inputs, images, image_sizes, modalities, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`inputs_embeds` is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m images \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 131\u001b[0m     (inputs, position_ids, attention_mask, _, inputs_embeds, _) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_inputs_labels_for_multimodal\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    133\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_model()\u001b[38;5;241m.\u001b[39membed_tokens(inputs)\n",
      "File \u001b[1;32mc:\\Users\\nikit\\Desktop\\\\\\\\LLaVA-NeXT\\llava\\model\\llava_arch.py:279\u001b[0m, in \u001b[0;36mLlavaMetaForCausalLM.prepare_inputs_labels_for_multimodal\u001b[1;34m(self, input_ids, position_ids, attention_mask, past_key_values, labels, images, modalities, image_sizes)\u001b[0m\n\u001b[0;32m    277\u001b[0m concat_images \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([image \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images_list], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    278\u001b[0m split_sizes \u001b[38;5;241m=\u001b[39m [image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images_list]\n\u001b[1;32m--> 279\u001b[0m encoded_image_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconcat_images\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;66;03m# image_features,all_faster_video_features = self.encode_multimodals(concat_images, video_idx_in_batch, split_sizes)\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \n\u001b[0;32m    282\u001b[0m \u001b[38;5;66;03m# This is a list, each element is [num_images, patch * patch, dim]\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;66;03m# rank_print(f\"Concat images : {concat_images.shape}\")\u001b[39;00m\n\u001b[0;32m    284\u001b[0m encoded_image_features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msplit(encoded_image_features, split_sizes)\n",
      "File \u001b[1;32mc:\\Users\\nikit\\Desktop\\\\\\\\LLaVA-NeXT\\llava\\model\\llava_arch.py:193\u001b[0m, in \u001b[0;36mLlavaMetaForCausalLM.encode_images\u001b[1;34m(self, images)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode_images\u001b[39m(\u001b[38;5;28mself\u001b[39m, images):\n\u001b[1;32m--> 193\u001b[0m     image_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_vision_tower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;66;03m# image_features = self.get_model().vision_resampler(image_features, images=images)\u001b[39;00m\n\u001b[0;32m    195\u001b[0m     image_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_model()\u001b[38;5;241m.\u001b[39mmm_projector(image_features)\n",
      "File \u001b[1;32mc:\\Users\\nikit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nikit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nikit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\accelerate\\hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[1;34m(module, *args, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[1;32mc:\\Users\\nikit\\Desktop\\\\\\\\LLaVA-NeXT\\llava\\model\\multimodal_encoder\\siglip_encoder.py:585\u001b[0m, in \u001b[0;36mSigLipVisionTower.forward\u001b[1;34m(self, images)\u001b[0m\n\u001b[0;32m    583\u001b[0m         image_features\u001b[38;5;241m.\u001b[39mappend(image_feature)\n\u001b[0;32m    584\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 585\u001b[0m     image_forward_outs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvision_tower\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    586\u001b[0m     image_features \u001b[38;5;241m=\u001b[39m image_forward_outs\u001b[38;5;241m.\u001b[39mhidden_states[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(images\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    587\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m image_features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m729\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\nikit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nikit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nikit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\accelerate\\hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[1;34m(module, *args, **kwargs)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_forward\u001b[39m(module, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 165\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hf_hook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mno_grad:\n\u001b[0;32m    167\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[1;32mc:\\Users\\nikit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\accelerate\\hooks.py:364\u001b[0m, in \u001b[0;36mAlignDevicesHook.pre_forward\u001b[1;34m(self, module, *args, **kwargs)\u001b[0m\n\u001b[0;32m    353\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_pointers_to_remove\u001b[38;5;241m.\u001b[39madd((value\u001b[38;5;241m.\u001b[39mdata_ptr(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device))\n\u001b[0;32m    355\u001b[0m         set_module_tensor_to_device(\n\u001b[0;32m    356\u001b[0m             module,\n\u001b[0;32m    357\u001b[0m             name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    361\u001b[0m             tied_params_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map,\n\u001b[0;32m    362\u001b[0m         )\n\u001b[1;32m--> 364\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_device\u001b[49m\u001b[43m)\u001b[49m, send_to_device(\n\u001b[0;32m    365\u001b[0m     kwargs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device, skip_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_keys\n\u001b[0;32m    366\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\nikit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\accelerate\\utils\\operations.py:175\u001b[0m, in \u001b[0;36msend_to_device\u001b[1;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[1;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhonor_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_keys\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, Mapping):\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(skip_keys, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\nikit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\accelerate\\utils\\operations.py:82\u001b[0m, in \u001b[0;36mhonor_type\u001b[1;34m(obj, generator)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(obj)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(generator))\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nikit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\accelerate\\utils\\operations.py:176\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m honor_type(\n\u001b[1;32m--> 176\u001b[0m         tensor, (\u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_keys\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tensor)\n\u001b[0;32m    177\u001b[0m     )\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, Mapping):\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(skip_keys, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\nikit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\accelerate\\utils\\operations.py:156\u001b[0m, in \u001b[0;36msend_to_device\u001b[1;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[0;32m    154\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxpu:0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# .to() doesn't accept non_blocking as kwarg\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Cannot copy out of meta tensor; no data!"
     ]
    }
   ],
   "source": [
    "from operator import attrgetter\n",
    "from llava.model.builder import load_pretrained_model\n",
    "from llava.mm_utils import get_model_name_from_path, process_images, tokenizer_image_token\n",
    "from llava.constants import IMAGE_TOKEN_INDEX, DEFAULT_IMAGE_TOKEN, DEFAULT_IM_START_TOKEN, DEFAULT_IM_END_TOKEN, IGNORE_INDEX\n",
    "from llava.conversation import conv_templates, SeparatorStyle\n",
    "\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "import copy\n",
    "import warnings\n",
    "from decord import VideoReader, cpu\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Load the OneVision model\n",
    "pretrained = \"lmms-lab/llava-onevision-qwen2-7b-ov\"\n",
    "model_name = \"llava_qwen\"\n",
    "device = \"cpu\"\n",
    "device_map = \"auto\"\n",
    "llava_model_args = {\n",
    "    \"multimodal\": True,\n",
    "}\n",
    "tokenizer, model, image_processor, max_length = load_pretrained_model(pretrained, None, model_name, device_map=device_map, attn_implementation=\"sdpa\", **llava_model_args)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# Function to extract frames from video\n",
    "def load_video(video_path, max_frames_num):\n",
    "    if type(video_path) == str:\n",
    "        vr = VideoReader(video_path, ctx=cpu(0))\n",
    "    else:\n",
    "        vr = VideoReader(video_path[0], ctx=cpu(0))\n",
    "    total_frame_num = len(vr)\n",
    "    uniform_sampled_frames = np.linspace(0, total_frame_num - 1, max_frames_num, dtype=int)\n",
    "    frame_idx = uniform_sampled_frames.tolist()\n",
    "    spare_frames = vr.get_batch(frame_idx).asnumpy()\n",
    "    return spare_frames  # (frames, height, width, channels)\n",
    "\n",
    "\n",
    "# Load and process video\n",
    "video_path = \"../111.mp4\"\n",
    "video_frames = load_video(video_path, 16)[:2:]\n",
    "print(video_frames.shape) # (16, 1024, 576, 3)\n",
    "image_tensors = []\n",
    "frames = image_processor.preprocess(video_frames, return_tensors=\"pt\")[\"pixel_values\"].half().to(device)\n",
    "image_tensors.append(frames)\n",
    "\n",
    "# Prepare conversation input\n",
    "conv_template = \"qwen_1_5\"\n",
    "question = f\"{DEFAULT_IMAGE_TOKEN}\\n ,        ?\"\n",
    "\n",
    "conv = copy.deepcopy(conv_templates[conv_template])\n",
    "conv.append_message(conv.roles[0], question)\n",
    "conv.append_message(conv.roles[1], None)\n",
    "prompt_question = conv.get_prompt()\n",
    "\n",
    "input_ids = tokenizer_image_token(prompt_question, tokenizer, IMAGE_TOKEN_INDEX, return_tensors=\"pt\").unsqueeze(0).to(device)\n",
    "image_sizes = [frame.size for frame in video_frames]\n",
    "\n",
    "print(image_tensors[0].shape)\n",
    "\n",
    "# Generate response\n",
    "cont = model.generate(\n",
    "    input_ids,\n",
    "    images=image_tensors,\n",
    "    image_sizes=image_sizes,\n",
    "    do_sample=False,\n",
    "    temperature=0,\n",
    "    max_new_tokens=1024,\n",
    "    modalities=[\"video\"],\n",
    ")\n",
    "text_outputs = tokenizer.batch_decode(cont, skip_special_tokens=True)\n",
    "print(text_outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f56ed5347c42472987a1322b25140f9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.41k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nikit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\nikit\\.cache\\huggingface\\hub\\models--llava-hf--LLaVA-NeXT-Video-7B-hf. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Unrecognized keys in `rope_scaling` for 'rope_type'='linear': {'type'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85801dd691434e9fb3c388b2e4eb745b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/70.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1adefc663100414e944f7a7d8b32dfc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d0b83b5dabc4ecda72290fbc9040355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab697df51b81471a967af379117a9933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "907f2126556a4bc2be4d6f27416ba05e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.18G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e68d4adcdd3748bab66153ab97098aa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1015f47e0ca640308d5ae6ece7cb7e81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82571de3d73844548b74c42a8e136c33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/741 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f3d5ae374e4472d8b519c63722d5e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.36k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50b123bfa56c4cbaad254dceff734dac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27e97656343b412ba1533423a198ec20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d0c5d8599524594abe6c61784d84cb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/43.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f304bb56f5f54368b81a0ec2ac4525ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/552 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e23100742c464bbaeac22350618e95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.json:   0%|          | 0.00/838 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid filename: cannot handle filename '..\\111_7.mp4' on Windows. Please ask the repository owner to rename this file.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 53\u001b[0m\n\u001b[0;32m     40\u001b[0m conversation \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     41\u001b[0m     {\n\u001b[0;32m     42\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m     },\n\u001b[0;32m     49\u001b[0m ]\n\u001b[0;32m     51\u001b[0m prompt \u001b[38;5;241m=\u001b[39m processor\u001b[38;5;241m.\u001b[39mapply_chat_template(conversation, add_generation_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 53\u001b[0m video_path \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mraushan-testing-hf/videos-test\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../111_7.mp4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m container \u001b[38;5;241m=\u001b[39m av\u001b[38;5;241m.\u001b[39mopen(video_path)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# sample uniformly 8 frames from the video, can sample more for longer videos\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nikit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nikit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:862\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[0;32m    842\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[0;32m    843\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[0;32m    844\u001b[0m         local_dir\u001b[38;5;241m=\u001b[39mlocal_dir,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    859\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m    860\u001b[0m     )\n\u001b[0;32m    861\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[0;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[0;32m    866\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[0;32m    871\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[0;32m    877\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nikit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:912\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[1;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[0;32m    910\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    911\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m relative_filename\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m..\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m relative_filename:\n\u001b[1;32m--> 912\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    913\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid filename: cannot handle filename \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrelative_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m on Windows. Please ask the repository\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m owner to rename this file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    915\u001b[0m         )\n\u001b[0;32m    917\u001b[0m \u001b[38;5;66;03m# if user provides a commit_hash and they already have the file on disk, shortcut everything.\u001b[39;00m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m REGEX_COMMIT_HASH\u001b[38;5;241m.\u001b[39mmatch(revision):\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid filename: cannot handle filename '..\\111_7.mp4' on Windows. Please ask the repository owner to rename this file."
     ]
    }
   ],
   "source": [
    "import av\n",
    "import torch\n",
    "import numpy as np\n",
    "from huggingface_hub import hf_hub_download\n",
    "from transformers import LlavaNextVideoProcessor, LlavaNextVideoForConditionalGeneration\n",
    "\n",
    "model_id = \"llava-hf/LLaVA-NeXT-Video-7B-hf\"\n",
    "\n",
    "model = LlavaNextVideoForConditionalGeneration.from_pretrained(\n",
    "    model_id, \n",
    "    torch_dtype=torch.float16, \n",
    "    low_cpu_mem_usage=True, \n",
    ").to(0)\n",
    "\n",
    "processor = LlavaNextVideoProcessor.from_pretrained(model_id)\n",
    "\n",
    "def read_video_pyav(container, indices):\n",
    "    '''\n",
    "    Decode the video with PyAV decoder.\n",
    "    Args:\n",
    "        container (`av.container.input.InputContainer`): PyAV container.\n",
    "        indices (`List[int]`): List of frame indices to decode.\n",
    "    Returns:\n",
    "        result (np.ndarray): np array of decoded frames of shape (num_frames, height, width, 3).\n",
    "    '''\n",
    "    frames = []\n",
    "    container.seek(0)\n",
    "    start_index = indices[0]\n",
    "    end_index = indices[-1]\n",
    "    for i, frame in enumerate(container.decode(video=0)):\n",
    "        if i > end_index:\n",
    "            break\n",
    "        if i >= start_index and i in indices:\n",
    "            frames.append(frame)\n",
    "    return np.stack([x.to_ndarray(format=\"rgb24\") for x in frames])\n",
    "\n",
    "\n",
    "# define a chat history and use `apply_chat_template` to get correctly formatted prompt\n",
    "# Each value in \"content\" has to be a list of dicts with types (\"text\", \"image\", \"video\") \n",
    "conversation = [\n",
    "    {\n",
    "\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"    ?\"},\n",
    "            {\"type\": \"video\"},\n",
    "            ],\n",
    "    },\n",
    "]\n",
    "\n",
    "prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
    "\n",
    "video_path = hf_hub_download(repo_id=\"raushan-testing-hf/videos-test\", filename=\"../111.mp4\", repo_type=\"dataset\")\n",
    "container = av.open(video_path)\n",
    "\n",
    "# sample uniformly 8 frames from the video, can sample more for longer videos\n",
    "total_frames = container.streams.video[0].frames\n",
    "indices = np.arange(0, total_frames, total_frames / 8).astype(int)\n",
    "clip = read_video_pyav(container, indices)\n",
    "inputs_video = processor(text=prompt, videos=clip, padding=True, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "output = model.generate(**inputs_video, max_new_tokens=100, do_sample=False)\n",
    "print(processor.decode(output[0][2:], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "ER: \n",
      "   :              1.  12.16.  1  ,                     2.  12.17   1.1  1.2.                                       . ,        ? ASSISTANT:    ,         , :\n",
      "\n",
      "\n",
      "1.  ,         (,    ,            ).\n",
      "2.                   .\n",
      "\n",
      "\n",
      ",    ,   ,     ,    ,        .\n"
     ]
    }
   ],
   "source": [
    "def read_video_pyav(container, indices):\n",
    "    '''\n",
    "    Decode the video with PyAV decoder.\n",
    "    Args:\n",
    "        container (`av.container.input.InputContainer`): PyAV container.\n",
    "        indices (`List[int]`): List of frame indices to decode.\n",
    "    Returns:\n",
    "        result (np.ndarray): np array of decoded frames of shape (num_frames, height, width, 3).\n",
    "    '''\n",
    "    frames = []\n",
    "    container.seek(0)\n",
    "    start_index = indices[0]\n",
    "    end_index = indices[-1]\n",
    "    for i, frame in enumerate(container.decode(video=0)):\n",
    "        if i > end_index:\n",
    "            break\n",
    "        if i >= start_index and i in indices:\n",
    "            frames.append(frame)\n",
    "    return np.stack([x.to_ndarray(format=\"rgb24\") for x in frames])\n",
    "\n",
    "\n",
    "# define a chat history and use `apply_chat_template` to get correctly formatted prompt\n",
    "# Each value in \"content\" has to be a list of dicts with types (\"text\", \"image\", \"video\") \n",
    "conversation = [\n",
    "    {\n",
    "\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {'type': \"text\", \"text\": \"   : \\\n",
    "             1.  12.16.  1  ,        \\\n",
    "             2.  12.17   1.1  1.2.                    \\\n",
    "                   .\"},\n",
    "            {\"type\": \"text\", \"text\": \",        ?\"},\n",
    "            {\"type\": \"video\"},\n",
    "            ],\n",
    "    },\n",
    "]\n",
    "\n",
    "prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
    "\n",
    "container = av.open('v111.mp4')\n",
    "\n",
    "# sample uniformly 8 frames from the video, can sample more for longer videos\n",
    "total_frames = container.streams.video[0].frames\n",
    "indices = np.arange(0, total_frames, total_frames / 2).astype(int)\n",
    "clip = read_video_pyav(container, indices)\n",
    "inputs_video = processor(text=prompt, videos=clip, padding=True, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "print('start')\n",
    "output = model.generate(**inputs_video, max_new_tokens=1024, do_sample=False)\n",
    "print(processor.decode(output[0][2:], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
